{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyrew1JZqYfB"
      },
      "outputs": [],
      "source": [
        "!curl -LO https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip\n",
        "!unzip -qq captcha_images_v2.zip\n",
        "!pip install comet_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROKiWSM5qu6h"
      },
      "outputs": [],
      "source": [
        "from comet_ml import Experiment\n",
        "experiment = Experiment(\n",
        "  api_key = \"\",\n",
        "  project_name = \"\",\n",
        "  workspace=\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3-D0-JRCDwsV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import yaml\n",
        "\n",
        "data_dir = Path(\"./captcha_images_v2/\")\n",
        "\n",
        "f = open('parameters.yaml','r')\n",
        "parameters = yaml.safe_load(f)\n",
        "\n",
        "batch_size = parameters.get('batch_size')\n",
        "img_width = parameters.get('img_width')\n",
        "img_height = parameters.get('img_height')\n",
        "downsample_factor = parameters.get('downsample_factor')\n",
        "length_characters = parameters.get('length_characters')\n",
        "epochs = parameters.get('epochs')\n",
        "early_stopping_patience = parameters.get('early_stopping_patience')\n",
        "characters = parameters.get('vocabulary')\n",
        "\n",
        "\n",
        "experiment.log_parameters({\n",
        "    \"img_width\": img_width,\n",
        "    \"img_height\": img_height,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": epochs,\n",
        "    \"early_stopping_patience\": early_stopping_patience,\n",
        "    \"length_characters\":length_characters,\n",
        "    \"vocabulary\": vocabulary\n",
        "})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j1RppMGVGYZj"
      },
      "source": [
        "# Pre procesamiento ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Db4NznXhG3R3"
      },
      "outputs": [],
      "source": [
        "# mapeamos los carácteres para asignarles un número único\n",
        "char_to_num = layers.StringLookup(\n",
        "    vocabulary=list(characters), mask_token=None\n",
        ")\n",
        "\n",
        "# invertimos el mapeo para decodificar el mapeo anterior, para garantizar una correspondencia bidireccional\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JnyZhTkVHhXW"
      },
      "outputs": [],
      "source": [
        "from modules.utils import split_data\n",
        "\n",
        "# Obtenemos la lista de todas las imágenes\n",
        "images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
        "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = split_data(np.array(images), np.array(labels))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8dhSjTgMJWXM"
      },
      "source": [
        "# Guardamos en un dataset los datos transformados ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "csWMNUk2JX7_"
      },
      "outputs": [],
      "source": [
        "from modules.utils import encode_single_sample, decode_single_sample\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = (\n",
        "    train_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(1)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fSGfe9MZKKVz"
      },
      "source": [
        "# Creamos el modelo o arquitectura ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "muQG5zQwKPbo"
      },
      "outputs": [],
      "source": [
        "from modules.model import  model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zUuSzEGaNHFk"
      },
      "source": [
        "# Entrenamiento ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6C4f63dHtkFc"
      },
      "outputs": [],
      "source": [
        "# activamos la parada anticipada si es que en las siguientes x épocas\n",
        "# no hay una mejora significativa\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Crear un Callback personalizado para registrar métricas en Comet.ml\n",
        "class CometMetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        experiment.log_metric(\"loss\", logs[\"loss\"], step=epoch)\n",
        "        experiment.log_metric(\"val_loss\", logs[\"val_loss\"], step=epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIXQa_RVNItL",
        "outputId": "924653dc-6a6f-499c-a192-9ef380d09a73"
      },
      "outputs": [],
      "source": [
        "# Entrenando\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping, CometMetricsCallback()]\n",
        ")\n",
        "\n",
        "# Finalización del experimento de Comet.ml\n",
        "experiment.end()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inferimos ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hxT2jRxbQzY"
      },
      "outputs": [],
      "source": [
        "# quitamos la última capa\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from modules.utils import decode_batch_predictions\n",
        "\n",
        "num = random.randrange(len(y_valid))\n",
        "\n",
        "mm = encode_single_sample(x_valid[num],y_valid[num])\n",
        "imagen = tf.reshape(mm['image'], (1, 200, 50, 1))\n",
        "etiqueta = tf.expand_dims(mm['label'], axis=0)\n",
        "\n",
        "preds = prediction_model.predict(imagen)\n",
        "label = tf.strings.reduce_join(num_to_char(etiqueta)).numpy().decode(\"utf-8\")\n",
        "img = (imagen[num, :, :, 0] * 255).numpy().astype(np.uint8).T\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "print('texto de etiqueta: ', label)\n",
        "pred_texts = decode_batch_predictions(preds)\n",
        "print('texto predecido: ', pred_texts)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
